---
title: "Connect1-Stigma Study: Results"
output: 
  html_document:
    toc: TRUE
    toc_depth: 2
---
   
# Overview of results 
![](Summary.jpg)
  
**Load libraries**
```{r, echo=FALSE, message=FALSE}

library(ggplot2)
library(psych)
library(PredictABEL)
library(caret)
library(e1071)

# Fields' script for calculating different R-squared's
pseudoR2s <- function(LogModel) {
  dev <- LogModel$deviance
  nullDev <- LogModel$null.deviance
  modelN <- length(LogModel$fitted.values)
  R.l <- 1 - dev / nullDev
  R.cs <- 1 - exp(-(nullDev - dev) / modelN)
  R.n <- R.cs / (1 -(exp(-(nullDev / modelN))))
  cat("Pseudo R^2 for Logistic Regression\n")
  cat("Hosmer and Lemeshow", R.l, "\n")
  cat("Cox and Snell", R.cs, "\n")
  cat("Nagelkerke", R.n, "\n")
} 
```
   
# Dataset preparation and descriptive statistics
  
Read data: Connect_Data_20191025.csv
  
Remove those with missing age/sex, who are too young, and who have HA experience.
```{r, echo=FALSE, results='hide'}

orig <- read.csv("Connect_Data_20191025.csv", header=TRUE)

# must have known age and sex (134 either/both unknown), 50+ years old (6 too young), never used a HA (45 are experienced, 100+ are NA); note that some cases have more than one strike
data <- orig[which(is.na(orig$Q44) == FALSE & is.na(orig$Q43) == FALSE & orig$Q44 > 49.5 & orig$Q42 == "No"), ]

# tidying up
rm(list = c("orig"))
```
   
Get some descriptives for the Participants section of the manuscript.
```{r, eval=FALSE, include=FALSE}

# descriptives for paper

tapply(data$Q44, list(Sex = data$Q43), mean)
tapply(data$Q44, list(Sex = data$Q43), sd)
tapply(data$Q44, list(Sex = data$Q43), min)
tapply(data$Q44, list(Sex = data$Q43), max)

```
  
Rename variables, recode variables, and remove rows containing any missing cells for 28 predictors.
```{r, echo=FALSE, results='hide'}

# more user-friendly column names
data$Age <- data$Q44

data$Sex <- c(NA)
data$Sex[data$Q43 == "Male"] <- 1
data$Sex[data$Q43 == "Female"] <- 0
table(data$Q43, data$Sex)

data$Edu <- data$Q46_Corrected

data$Health <- data$Q53

data$QoL <- data$Q54

data$Accomp <- c(NA)
data$Accomp[data$Q45 == "Yes"] <- 1
data$Accomp[data$Q45 == "No"] <- 0
table(data$Q45, data$Accomp)

data$Married <- c(NA) 
data$Married[data$marital_recoded == "Married"] <- 1
data$Married[data$marital_recoded == "Sep_Divor"] <- 0
data$Married[data$marital_recoded == "Single"] <- 0
data$Married[data$marital_recoded == "Widowed"] <- 0
data$Married[data$marital_recoded == "Other"] <- 0
table(data$marital_recoded, data$Married)

data$Help_neighbours <- data$Q50_Corrected
table(data$Q50_Corrected, data$Help_neighbours)

data$Help_problems <- c(NA)
data$Help_problems[is.na(data$Q51)==FALSE & data$Q51 == "0"] <- 0
data$Help_problems[is.na(data$Q51)==FALSE & data$Q51 == "1_2"] <- 1
data$Help_problems[is.na(data$Q51)==FALSE & data$Q51 == "3_5"] <- 2
data$Help_problems[is.na(data$Q51)==FALSE & data$Q51 == "5+"] <- 3
table(data$Q51, data$Help_problems)

data$Concern <- data$Q52

data$Lonely <- data$Q55

# Q21
data$Soc_Suspect_HL <- c(NA)
data$Soc_Suspect_HL[data$Q21_Corrected != "0" & is.na(data$Q21_Corrected)==FALSE] <- 1
data$Soc_Suspect_HL[data$Q21_Corrected == "0" & is.na(data$Q21_Corrected)==FALSE] <- 0 
table(data$Q21_Corrected, data$Soc_Suspect_HL)

# Q22
data$Soc_Know_HL <- c(NA)
data$Soc_Know_HL[data$Q22_Corrected != "0" & is.na(data$Q22_Corrected)==FALSE] <- 1
data$Soc_Know_HL[data$Q22_Corrected == "0" & is.na(data$Q22_Corrected)==FALSE] <- 0 
table(data$Q22_Corrected, data$Soc_Know_HL)

# Q23
data$Soc_Discuss_HL <- c(NA)
data$Soc_Discuss_HL[data$Q23_Corrected != "0" & is.na(data$Q23_Corrected)==FALSE] <- 1
data$Soc_Discuss_HL[data$Q23_Corrected == "0" & is.na(data$Q23_Corrected)==FALSE] <- 0 
table(data$Q23_Corrected, data$Soc_Discuss_HL)

# Q24
data$Soc_Hearing_test <- c(NA)
data$Soc_Hearing_test[data$Q24_Corrected != "0" & is.na(data$Q24_Corrected)==FALSE] <- 1
data$Soc_Hearing_test[data$Q24_Corrected == "0" & is.na(data$Q24_Corrected)==FALSE] <- 0 
table(data$Q24_Corrected, data$Soc_Hearing_test)

# Q25
data$Soc_Obtain_HA <- c(NA)
data$Soc_Obtain_HA[data$Q25_Corrected != "0" & is.na(data$Q25_Corrected)==FALSE] <- 1
data$Soc_Obtain_HA[data$Q25_Corrected == "0" & is.na(data$Q25_Corrected)==FALSE] <- 0 
table(data$Q25_Corrected, data$Soc_Obtain_HA)

# Q26
data$Soc_Sometimes_use <- c(NA)
data$Soc_Sometimes_use[data$Q26_Corrected != "0" & is.na(data$Q26_Corrected)==FALSE] <- 1
data$Soc_Sometimes_use[data$Q26_Corrected == "0" & is.na(data$Q26_Corrected)==FALSE] <- 0 
table(data$Q26_Corrected, data$Soc_Sometimes_use)

# Q27
data$Soc_Regular_use <- c(NA)
data$Soc_Regular_use[data$Q27_Corrected != "0" & is.na(data$Q27_Corrected)==FALSE] <- 1
data$Soc_Regular_use[data$Q27_Corrected == "0" & is.na(data$Q27_Corrected)==FALSE] <- 0 
table(data$Q27_Corrected, data$Soc_Regular_use)

# Q28
data$Soc_Very_positive <- c(NA)
data$Soc_Very_positive[data$Q28_Corrected != "0" & is.na(data$Q28_Corrected)==FALSE] <- 1
data$Soc_Very_positive[data$Q28_Corrected == "0" & is.na(data$Q28_Corrected)==FALSE] <- 0
table(data$Q28_Corrected, data$Soc_Very_positive)

# Q29
data$Soc_Somewhat_positive <- c(NA)
data$Soc_Somewhat_positive[data$Q29_Corrected != "0" & is.na(data$Q29_Corrected)==FALSE] <- 1
data$Soc_Somewhat_positive[data$Q29_Corrected == "0" & is.na(data$Q29_Corrected)==FALSE] <- 0 
table(data$Q29_Corrected, data$Soc_Somewhat_positive)

# Q30
data$Soc_Somewhat_negative <- c(NA)
data$Soc_Somewhat_negative[data$Q30_Corrected != "0" & is.na(data$Q30_Corrected)==FALSE] <- 1
data$Soc_Somewhat_negative[data$Q30_Corrected == "0" & is.na(data$Q30_Corrected)==FALSE] <- 0 
table(data$Q30_Corrected, data$Soc_Somewhat_negative)

# Q31
data$Soc_Very_negative <- c(NA)
data$Soc_Very_negative[data$Q31_Corrected != "0" & is.na(data$Q31_Corrected)==FALSE] <- 1
data$Soc_Very_negative[data$Q31_Corrected == "0" & is.na(data$Q31_Corrected)==FALSE] <- 0 
table(data$Q31_Corrected, data$Soc_Very_negative)

#Q56 overall hearing ability
data$Ability <- data$Q56_Corrected
table(data$Ability)

# outcome measure
data$Purchased_HA <- c(NA)
data$Purchased_HA[data$HA.Purchase == "Yes" & is.na(data$HA.Purchase)==FALSE] <- 1
data$Purchased_HA[data$HA.Purchase == "No" & is.na(data$HA.Purchase)==FALSE] <- 0
table(data$HA.Purchase, data$Purchased_HA)

# only rows with all variables present
data2 <- subset(data, 
  is.na(data$Age)==F & 
  is.na(data$PTA4_better_ear)==F & 
  is.na(data$HHIE_total)==F & 
  is.na(data$Ability)==F &  
  is.na(data$Sex)==F & 
  is.na(data$Edu)==F &  
  is.na(data$Married)==F &  
  is.na(data$Health)==F & 
  is.na(data$QoL)==F & 
  is.na(data$Help_neighbours)==F &  
  is.na(data$Help_problems)==F &
  is.na(data$Concern)==F & 
  is.na(data$Lonely)==F &   
  is.na(data$Sub_Age_avg)==F &  
  is.na(data$Age_stigma_avg)==F & 
  is.na(data$HA_stigma_avg)==F & 
  is.na(data$Accomp)==F & 
  is.na(data$Soc_Suspect_HL)==F &
  is.na(data$Soc_Know_HL)==F &
  is.na(data$Soc_Discuss_HL)==F &
  is.na(data$Soc_Hearing_test)==F &
  is.na(data$Soc_Obtain_HA)==F &   
  is.na(data$Soc_Sometimes_use)==F &
  is.na(data$Soc_Regular_use)==F &
  is.na(data$Soc_Very_positive)==F &
  is.na(data$Soc_Somewhat_positive)==F &
  is.na(data$Soc_Somewhat_negative)==F &
  is.na(data$Soc_Very_negative)==F & 
  is.na(data$Purchased_HA)==F)

rm(list = c("data")) # tidying up
```
  
Get numbers for Table 1 in manuscript.
```{r, eval=FALSE, include=FALSE}

# Repeat for SD, Min, Max
#tapply(data2$Age, list(Group = data2$HA.Purchase), mean) 
mean(data2$Age) 
mean(data2$PTA4_better_ear) 
mean(data2$HHIE_total)  
mean(data2$Ability) 
mean(data2$Health)
mean(data2$QoL) 
mean(data2$Edu)
mean(data2$Help_neighbours) 
mean(data2$Help_problems) 
mean(data2$Concern) 
mean(data2$Lonely) 
mean(data2$Sub_Age_avg) 
mean(data2$Age_stigma_avg) 
mean(data2$HA_stigma_avg)

#table(data2$Sex, data2$HA.Purchase) 
prop.table(table(data2$Sex))*100 
prop.table(table(data2$Married))*100
prop.table(table(data2$Accomp))*100 
prop.table(table(data2$Soc_Suspect_HL))*100
prop.table(table(data2$Soc_Know_HL))*100
prop.table(table(data2$Soc_Discuss_HL))*100
prop.table(table(data2$Soc_Hearing_test))*100
prop.table(table(data2$Soc_Obtain_HA))*100 
prop.table(table(data2$Soc_Sometimes_use))*100
prop.table(table(data2$Soc_Regular_use))*100
prop.table(table(data2$Soc_Very_positive))*100
prop.table(table(data2$Soc_Somewhat_positive))*100
prop.table(table(data2$Soc_Somewhat_negative))*100
prop.table(table(data2$Soc_Very_negative))*100

```
    
Plot audiogram for Figure 2 in manuscript.
```{r, eval=FALSE, include=FALSE}

# New dataset with better and worse ears
audio <- data2[, c(1, 83:94)]

audio$Better_250 <- pmin(audio$LE250c, audio$RE250c)
audio$Better_500 <- pmin(audio$LE500c, audio$RE500c)
audio$Better_1000 <- pmin(audio$LE1000c, audio$RE1000c)
audio$Better_2000 <- pmin(audio$LE2000c, audio$RE2000c)
audio$Better_4000 <- pmin(audio$LE4000c, audio$RE4000c)
audio$Better_8000 <- pmin(audio$LE8000c, audio$RE8000c)

audio$Worse_250 <- pmax(audio$LE250c, audio$RE250c)
audio$Worse_500 <- pmax(audio$LE500c, audio$RE500c)
audio$Worse_1000 <- pmax(audio$LE1000c, audio$RE1000c)
audio$Worse_2000 <- pmax(audio$LE2000c, audio$RE2000c)
audio$Worse_4000 <- pmax(audio$LE4000c, audio$RE4000c)
audio$Worse_8000 <- pmax(audio$LE8000c, audio$RE8000c)

head(audio)

# Specify x-axis datapoints
freq <- c(250, 500, 1000, 2000, 4000, 8000)

# Calculate y-axis means and error bars for plotting
better.m <- as.vector(colMeans(audio[, c(14:19)], na.rm=TRUE))
better.se <- as.vector(sapply(X = audio[, c(14:19)], FUN = sd, na.rm=TRUE)/(1868^0.5))
better.sd <- as.vector(sapply(X = audio[, c(14:19)], FUN = sd, na.rm=TRUE))
worse.m <- as.vector(colMeans(audio[, c(20:25)], na.rm=TRUE))
worse.se <- as.vector(sapply(X = audio[, c(20:25)], FUN = sd, na.rm=TRUE)/(1868^0.5))
worse.sd <- as.vector(sapply(X = audio[, c(20:25)], FUN = sd, na.rm=TRUE))

# Combine x and y points into dataframe for plotting
audio2 <- data.frame(rep(freq, 2))
colnames(audio2) <- c('freq')
audio2$ear <- c(rep('Better', 6), rep('Worse', 6))
audio2$threshold <- rep(NA, 12)
audio2$threshold[1:6] <- better.m
audio2$threshold[7:12] <- worse.m
audio2$sd <- rep(NA, 12)
audio2$sd[1:6] <- better.sd
audio2$sd[7:12] <- worse.sd

# exported as 6 by 9
ggplot(data = audio2, aes(x = freq, y = threshold, group = ear, shape = ear)) + 
  geom_point(size = 3) +
    scale_shape_manual(name = "Ear", values = c(19, 17)) +
  geom_errorbar(data = audio2, 
    aes(x = freq, ymin = (threshold - sd), ymax = (threshold + sd)), 
    width = 0.05, position = position_dodge(0.01)) +
  geom_line(aes(linetype = ear), color = "black") + 
    scale_linetype_manual(values = c("solid", "longdash")) + 
    guides(linetype = FALSE) + 
  labs(x = "Frequency (Hz)", y = "Threshold (dB HL)") +
  scale_y_reverse(limits = c(80, 0), breaks = seq(0, 80, by = 10)) + 
  scale_x_log10(breaks = unique(audio2$freq), labels = unique(c('250', '500', '1000', '2000', '4000', '8000'))) +
  theme_bw() + 
  theme(axis.title = element_text(size = 25), 
    axis.text = element_text(colour = "black", size = 20), 
    text = element_text(size = 20)) + 
  theme(panel.background = element_rect(color = "black", size = 1)) + 
  theme(legend.position = c(0.12, 0.15)) + 
    theme(legend.background = element_rect(fill = "white", color = "black"))

rm(list = c('audio', 'audio2', 'better.m', 'better.sd', 'better.se', 
     'worse.m', 'worse.sd', 'worse.se', 'freq'))

```
   
# Participant overlap according to three inclusion criteria

## All participants
  
```{r, eval=FALSE, include=FALSE}

# numbers for Venn diagram: all participants with complete data
pta <- subset(data2, PTA4_better_ear > 25.0)
hhie <- subset(data2, HHIE_total > 9)
ab <- subset(data2, Ability < 8)

check <- subset(data2, PTA4_better_ear > 25.0 & HHIE_total > 9 & Ability < 8) #459 all bad
check <- subset(data2, PTA4_better_ear > 25.0 & HHIE_total < 10 & Ability > 7) #120 PTA only
check <- subset(data2, PTA4_better_ear <= 25.0 & HHIE_total > 9 & Ability > 7) #168 HHIE only
check <- subset(data2, PTA4_better_ear <= 25.0 & HHIE_total < 10 & Ability < 8) #149 Ability only
check <- subset(data2, PTA4_better_ear > 25.0 & HHIE_total > 9 & Ability > 7) #82 PTA & HHIE bad, Ability good
check <- subset(data2, PTA4_better_ear <= 25.0 & HHIE_total > 9 & Ability < 8) #383 HHIE Ability bad, PTA good
check <- subset(data2, PTA4_better_ear > 25.0 & HHIE_total < 10 & Ability < 8) #92 PTA & Ability bad, HHIE good
check <- subset(data2, PTA4_better_ear <= 25.0 & HHIE_total < 10 & Ability > 7) #416 all good
round(c(459, 120, 168, 149, 82, 383, 92, 416)/1869, 2)
rm(check)

```
   
```{r, eval=FALSE, include=FALSE}

# numbers for Venn diagram: participants who obtained HA
ha <- subset(data2, HA.Purchase == "Yes")

#pta <- subset(ha, PTA4_better_ear > 25.0) #149
#hhie <- subset(ha, HHIE_total > 9) #158
#ab <- subset(ha, Ability < 8) #156

check.all <- subset(ha, PTA4_better_ear > 25.0 & HHIE_total > 9 & Ability < 8) #108 all bad
check.pta <- subset(ha, PTA4_better_ear > 25.0 & HHIE_total < 10 & Ability > 7) #18 PTA only
check.hhie <- subset(ha, PTA4_better_ear <= 25.0 & HHIE_total > 9 & Ability > 7) #7 HHIE only
check.ab <- subset(ha, PTA4_better_ear <= 25.0 & HHIE_total < 10 & Ability < 8) #4 Ability only
check.pta.hhie <- subset(ha, PTA4_better_ear > 25.0 & HHIE_total > 9 & Ability > 7) #11 PTA & HHIE bad, Ability good
check.hhie.ab <- subset(ha, PTA4_better_ear <= 25.0 & HHIE_total > 9 & Ability < 8) #32 HHIE & Ability bad, PTA good
check.pta.ab <- subset(ha, PTA4_better_ear > 25.0 & HHIE_total < 10 & Ability < 8) #12 PTA & Ability bad, HHIE good
check.none <- subset(ha, PTA4_better_ear <= 25.0 & HHIE_total < 10 & Ability > 7) #11 all good

round(c(108, 18, 7, 4, 11, 32, 12, 11)/203, 2)
18+12+4+11+108+32+7+11
rm(list = c('check.all', 'check.pta', 'check.hhie', 'check.ab', 'check.pta.hhie', 'check.hhie.ab', 'check.pta.ab', 'check.none', 'ha'))

```
    
![](Venn_diagram_all.jpg)

## Only those who purchased HA
![](Venn_diagram_HA.jpg)
  
# Correlation among variables

## PTA, HHIE, Hearing Ability
```{r, echo=FALSE, results='hide', fig.keep='all'}

with(data2, cor.test(PTA4_better_ear, HHIE_total)) #r = 0.3408834, p-value < 2.2e-16
with(data2, cor.test(PTA4_better_ear, Ability)) #r = -0.3502925, p-value < 2.2e-16
with(data2, cor.test(HHIE_total, Ability)) #r = -0.6002793, p-value < 2.2e-16

data2$col.alpha <- rep(0.5, nrow(data2))
data2$col.alpha[data2$Purchased_HA == 1] <- 1

m1 <- lm(data2$HHIE_total ~ data2$PTA4_better_ear)
ggplot(data2, aes(x = PTA4_better_ear, y = jitter(HHIE_total), fill = HA.Purchase, shape = HA.Purchase)) + 
  geom_point(size = 2, colour = "black", alpha = data2$col.alpha) +
  scale_shape_manual(name = "Purchased HA", values = c(1, 24)) + 
  scale_fill_manual(name = "Purchased HA", values = c(NA, "red")) + 
  coord_cartesian(xlim=c(0, 80), ylim=c(0, 40)) +
  xlab('PTA4 better ear (dB HL)') +
  ylab('HHIE total score') + 
  geom_abline(slope = m1$coefficients[2], intercept = m1$coefficients[1], colour = "black") + 
  annotate("text", x=70, y=5, label = "r = 0.34", size = 5) + 
  theme_bw() +
  theme(axis.title = element_text(size = 25, face="bold"), 
    axis.text = element_text(colour = "black", size = 20, face="bold"), 
    text = element_text(size = 20))

m2 <- lm(data2$Ability ~ data2$PTA4_better_ear)
ggplot(data2, aes(x = PTA4_better_ear, y = jitter(Ability, factor = 1.5), fill = HA.Purchase, shape = HA.Purchase)) + 
  geom_point(size = 2, colour = "black", alpha = data2$col.alpha) +
  scale_shape_manual(name = "Purchased HA", values = c(1, 24)) + 
  scale_fill_manual(name = "Purchased HA", values = c("black", "red")) + 
  coord_cartesian(xlim=c(0, 80), ylim=c(0, 11)) +
  scale_y_continuous(breaks = seq(0, 10, by = 2)) + 
  xlab('PTA4 better ear (dB HL)') +
  ylab('Hearing ability') + 
  geom_abline(slope = m2$coefficients[2], intercept = m2$coefficients[1], colour = "black") + 
  annotate("text", x=70, y=1, label = "r = -0.35", size = 5) + 
  theme_bw() +
  theme(axis.title = element_text(size = 25, face="bold"), 
    axis.text = element_text(colour = "black", size = 20, face="bold"), 
    text = element_text(size = 20))

m3 <- lm(data2$Ability ~ data2$HHIE_total)
ggplot(data2, aes(x = jitter(HHIE_total, factor = 1.25), y = jitter(Ability, factor = 1.25), fill = HA.Purchase, shape = HA.Purchase)) + 
  geom_point(size = 2, colour = "black", alpha = data2$col.alpha) +
  scale_shape_manual(name = "Purchased HA", values = c(1, 24)) + 
  scale_fill_manual(name = "Purchased HA", values = c("black", "red")) + 
  coord_cartesian(xlim=c(0, 40), ylim=c(0, 11)) +
  scale_y_continuous(breaks = seq(0, 10, by = 2)) + 
  xlab('HHIE total score') +
  ylab('Ability') + 
  geom_abline(slope = m3$coefficients[2], intercept = m3$coefficients[1], colour = "black") + 
  annotate("text", x=35, y=1, label = "r = -0.60", size = 5) + 
  theme_bw() +
  theme(axis.title = element_text(size = 25, face="bold"), 
    axis.text = element_text(colour = "black", size = 20, face="bold"), 
    text = element_text(size = 20))

```

Note: A few participants bought HA despite good PTA and/or HHIE scores.
```{r, eval=FALSE, include=FALSE}

# Who bought HA with good PTA and HHIE?

table(data2$HA.Purchase)

ha <- subset(data2, HA.Purchase == "Yes" & PTA4_better_ear <= 25)
audio <- ha[, c('ID', 'HA.Purchase', 'Age', 'HHIE_total', 'PTA4_left', 'PTA4_right', 'PTA4_better_ear', 
  'LE250c',	'LE500c', 'LE1000c', 'LE2000c', 'LE4000c', 'LE8000c', 
  'RE250c', 'RE500c', 'RE1000c', 'RE2000c', 'RE4000c', 'RE8000c')]
```

## Subjective Age, Age Stigma, and HA Stigma
```{r, echo=FALSE}

lowerMat(cor(data.frame(data2$Q1_Corrected, data2$Q2_Corrected, data2$Q3_Corrected), use="complete.obs", method="pearson"))

lowerMat(cor(data.frame(data2$Q4_Corrected, data2$Q5_Corrected, data2$Q6_Corrected, data2$Q7_Corrected, data2$Q8_Corrected), use="complete.obs", method="pearson"))

lowerMat(cor(data.frame(data2$Q9_Corrected, data2$Q10_Corrected, data2$Q11_Corrected, data2$Q12_Corrected), use="complete.obs", method="pearson"))
```
  
# PTA
Include only participants with PTA4 > 25 dB HL in the better ear (case count and %).
```{r, echo=FALSE}
pta <- subset(data2, PTA4_better_ear > 25.0)
length(pta[,1])
length(pta[,1]) / length(data2[,1]) * 100
```
 
Proportion of people who purchased hearing aids
```{r, echo=FALSE}
table(pta$HA.Purchase)/length(pta[,1]) #0.1978752
```
    
## PTA: Logistic regression with backwards elimination 
The full model contains 28 predictors.
```{r, evaluate = FALSE, include = FALSE}

m.pta <- glm(Purchased_HA ~ 
  Age +  
  PTA4_better_ear +
  HHIE_total +
  Ability +
  Sex +
  Edu +
  Married +
  Health +
  QoL +
  Help_neighbours +
  Help_problems +
  Concern +
  Lonely +
  Sub_Age_avg +
  Age_stigma_avg +
  HA_stigma_avg +
  Accomp +
  Soc_Suspect_HL +
  Soc_Know_HL +
  Soc_Discuss_HL +
  Soc_Hearing_test +
  Soc_Obtain_HA +
  Soc_Sometimes_use +
  Soc_Regular_use +
  Soc_Very_positive +
  Soc_Somewhat_positive +
  Soc_Somewhat_negative +
  Soc_Very_negative, 
family = binomial("logit"), data = pta)
```
  
With a backwards elimination procedure, the final model is:
```{r, echo=FALSE, fig.show='hide', message = FALSE}

# step(object = m.pta, direction = c("backward"), trace = 1)

# Only including significant predictors after backwards elimination procedure (dropped additional variables)

m.final <- glm(Purchased_HA ~ Age + HHIE_total + HA_stigma_avg + Soc_Suspect_HL, 
  family = binomial("logit"), data = pta)

summary(m.final)

pseudoR2s(m.final)

pred <- predict.glm(m.final, newdata = subset(pta, select=c('Age', 'HHIE_total', 'HA_stigma_avg', 'Soc_Suspect_HL')), type = 'response')
pred.binary <- ifelse(pred > 0.1978752, 1, 0)
    
plotROC(data = pta, 
  cOutcome = 134, 
  predrisk = pred.binary,
  plottitle = "ROC plot", 
  xlabel = "1 - Specificity", 
  ylabel = "Sensitivity")
# AUC [95% CI] for the model 1 :  0.621 [ 0.577  -  0.664 ]

confusionMatrix(data = as.factor(pred.binary), reference = as.factor(pta$Purchased_HA), positive = c("1"))
```
  
## PTA: Net Reclassification Improvement  
"Basic" model: Age only
```{r, echo=FALSE}
m.basic <- glm(Purchased_HA ~ Age, family = binomial("logit"), data = pta)

basic.fitted.results <- predict.glm(m.basic, newdata = subset(pta, select=c('Age')), type = 'response')

summary(m.basic)
```
 
Table of NRI values for 27 "novel" predictors
```{r, eval = FALSE, include = FALSE}

predictors <- c('PTA4_better_ear','HHIE_total','Ability','Sex','Edu','Married','Health','QoL',
'Help_neighbours','Help_problems','Concern','Lonely',
'Sub_Age_avg','Age_stigma_avg','HA_stigma_avg','Accomp',
'Soc_Suspect_HL','Soc_Know_HL','Soc_Discuss_HL','Soc_Hearing_test',
'Soc_Obtain_HA','Soc_Sometimes_use','Soc_Regular_use',
'Soc_Very_positive','Soc_Somewhat_positive','Soc_Somewhat_negative','Soc_Very_negative')

for (i in 1:27) {

new.formula <- as.formula(paste0("Purchased_HA ~ Age + ", predictors[i]))  
m.new <- glm(new.formula, family = binomial("logit"), data = pta)

new.fitted.results <- predict.glm(m.new, newdata = subset(pta, select=c('Age', predictors[i])), type = 'response')

print(predictors[i])
reclassification(data = pta, cOutcome = 134, predrisk1 = basic.fitted.results, predrisk2 = new.fitted.results, cutoff = c(0, 0.1978752, 1))
}
```
 
|Predictor|NRI|p-value| 
|-----|-----|-----|
|PTA4_better_ear|	-0.000400|	0.989590|
|HHIE_total	|0.140000	|0.003440|
|Ability	|-0.008500	|0.824360|
|Sex	|0.048500	|0.144430|
|Edu	|-0.003200	|0.850050|
|Married	|0.018600	|0.373270|
|Health	|0.025300	|0.195670|
|QoL	|0.031900	|0.233760|
|Help_neighbours	|0.000300	|0.991080|
|Help_problems	|0.015300	|0.435690|
|Concern	|0.016900|	0.495400|
|Lonely	|0.000000	|NA|
|Sub_Age_avg	|0.000200	|0.988380|
|Age_stigma_avg	|-0.018200|	0.517490|
|HA_stigma_avg	|0.025500	|0.488240|
|Accomp	|0.011700	|0.579330|
|Soc_Suspect_HL	|0.054100	|0.145060|
|Soc_Know_HL	|0.000000|	NA|
|Soc_Discuss_HL	|0.006700	|0.699190|
|Soc_Hearing_test	|0.015100	|0.422910|
|Soc_Obtain_HA  	|0.006900	|0.728710|
|Soc_Sometimes_use	|0.003700	|0.801540|
|Soc_Regular_use	|0.005100	|0.781160|
|Soc_Very_positive	|-0.001500	|0.968770|
|Soc_Somewhat_positive	|-0.008200	|0.324350|
|Soc_Somewhat_negative	|0.000300	|0.983420|
|Soc_Very_negative	|-0.009700	|0.471530|
  
## PTA: Evaluation of regression model containing NRI predictors  
```{r, echo=FALSE, fig.show='hide', message = FALSE}

m.nri <- glm(Purchased_HA ~ Age + HHIE_total, family = binomial("logit"), data = pta)
summary(m.nri)

exp(coef(m.nri))
exp(cbind(OR = coef(m.nri), confint(m.nri)))

pseudoR2s(m.nri)

pred.nri <- predict.glm(m.nri, newdata = subset(pta, select=c('Age', 'HHIE_total')), type = 'response')
pred.nri.binary <- ifelse(pred.nri > 0.1978752, 1, 0)

plotROC(data = pta, 
  cOutcome = 134, 
  predrisk = pred.nri.binary,
  plottitle = "ROC plot", 
  xlabel = "1 - Specificity", 
  ylabel = "Sensitivity")
#AUC [95% CI] for the model 1 :  0.629 [ 0.585  -  0.673 ] 

confusionMatrix(data = as.factor(pred.nri.binary), reference = as.factor(pta$Purchased_HA), positive = c("1"))
```
   
# HHIE-S
Include only participants with HHIE-S scores ≥ 10 (case count and %).
```{r, echo=FALSE}
hhie <- subset(data2, HHIE_total > 9)
length(hhie[,1])
length(hhie[,1]) / length(data2[,1]) * 100
```
 
Proportion of people who purchased hearing aids
```{r, echo=FALSE}
table(hhie$HA.Purchase)/length(hhie[,1]) #0.1446886
```
   
## HHIE-S: Logistic regression with backwards elimination
The full model contains 28 predictors.
```{r, evaluate = FALSE, include = FALSE}

m.hhie <- glm(Purchased_HA ~ 
  Age +  
  PTA4_better_ear +
  HHIE_total +
  Ability +
  Sex +
  Edu +
  Married +
  Health +
  QoL +
  Help_neighbours +
  Help_problems +
  Concern +
  Lonely +
  Sub_Age_avg +
  Age_stigma_avg +
  HA_stigma_avg +
  Accomp +
  Soc_Suspect_HL +
  Soc_Know_HL +
  Soc_Discuss_HL +
  Soc_Hearing_test +
  Soc_Obtain_HA +
  Soc_Sometimes_use +
  Soc_Regular_use +
  Soc_Very_positive +
  Soc_Somewhat_positive +
  Soc_Somewhat_negative +
  Soc_Very_negative, 
family = binomial("logit"), data = hhie)
```
  
With a backwards elimination procedure, the final model is:
```{r, echo=FALSE, fig.show='hide'}

# step(object = m.hhie, direction = c("backward"), trace = 1)
# Only including significant predictors after backwards elimination procedure (dropped additional variables)

m.final <- glm(Purchased_HA ~ Age + PTA4_better_ear + HHIE_total + Sub_Age_avg, 
    family = binomial("logit"), data = hhie)

summary(m.final)

pseudoR2s(m.final)

pred <- predict.glm(m.final, newdata = subset(hhie, select=c('Age', 'PTA4_better_ear', 'HHIE_total', 'Sub_Age_avg')), type = 'response')
pred.binary <- ifelse(pred > 0.1446886, 1, 0)
    
plotROC(data = hhie, 
  cOutcome = 134, 
  predrisk = pred.binary,
  plottitle = "ROC plot", 
  xlabel = "1 - Specificity", 
  ylabel = "Sensitivity")
# AUC [95% CI] for the model 1 :  0.665 [ 0.625  -  0.705 ] 

confusionMatrix(data = as.factor(pred.binary), reference = as.factor(hhie$Purchased_HA), positive = c("1"))
```

## HHIE-S: Net Reclassification Improvement 
"Basic" model: Age only
```{r, echo=FALSE}
m.basic <- glm(Purchased_HA ~ Age, family = binomial("logit"), data = hhie)

basic.fitted.results <- predict.glm(m.basic, newdata = subset(hhie, select=c('Age')), type = 'response')

summary(m.basic)
``` 
 
Table of NRI values for 27 "novel" predictors 
```{r, eval = FALSE, include = FALSE}

for (i in 1:27) {

new.formula <- as.formula(paste0("Purchased_HA ~ Age + ", predictors[i]))  
m.new <- glm(new.formula, family = binomial("logit"), data = hhie)

new.fitted.results <- predict.glm(m.new, newdata = subset(hhie, select=c('Age', predictors[i])), type = 'response')

print(predictors[i])
reclassification(data = hhie, cOutcome = 134, predrisk1 = basic.fitted.results, predrisk2 = new.fitted.results, cutoff = c(0, 0.1446886, 1))
}
```
 
|Predictor|NRI|p-value| 
|-----|-----|-----| 
|PTA4_better_ear|	0.1009|	0.01164|
|HHIE_total|	0.0702|	0.07463|
|Ability|	-0.0019|	0.95844|
|Sex	|-0.0054	|0.6254|
|Edu	|-0.0071	|0.6698|
|Married	|0.0055	|0.5760|
|Health	|0.0118	|0.4871|
|QoL	|-0.0043	|0.7918|
|Help_neighbours|	0.0000|	NA|
|Help_problems	|-0.0168	|0.2221|
|Concern	|0.0000|	NA|
|Lonely	|0.0000|	NA|
|Sub_Age_avg	|0.0305	|0.2274|
|Age_stigma_avg|	-0.0168|	0.2192|
|HA_stigma_avg|	-0.0181	|0.4279|
|Accomp|	0.0061|	0.5924|
|Soc_Suspect_HL|	-0.0255|	0.2464|
|Soc_Know_HL	|0.0075	|0.0079|
|Soc_Discuss_HL|	0.0000|	NA|
|Soc_Hearing_test	|-0.0211|	0.3117|
|Soc_Obtain_HA  	|-0.0020|	0.8374|
|Soc_Sometimes_use	|0.0120|	0.2425|
|Soc_Regular_use	|0.0076|	0.3039|
|Soc_Very_positive	|-0.0097|	0.7279|
|Soc_Somewhat_positive|	0.0003	|0.9807|
|Soc_Somewhat_negative|	0.0087	|0.2455|
|Soc_Very_negative	|0.0054	|0.0250|
 
## HHIE: Evaluation of regression model containing NRI predictors
```{r, echo=FALSE, fig.show='hide', message = FALSE}

m.nri <- glm(Purchased_HA ~ Age + PTA4_better_ear + Soc_Know_HL + Soc_Very_negative, 
  family = binomial("logit"), data = hhie)
summary(m.nri)

exp(coef(m.nri))
exp(cbind(OR = coef(m.nri), confint(m.nri)))

pseudoR2s(m.nri)

pred.nri <- predict.glm(m.nri, newdata = subset(hhie, select=c('Age', 'PTA4_better_ear', 'Soc_Know_HL', 'Soc_Very_negative')), type = 'response')
pred.nri.binary <- ifelse(pred.nri > 0.1446886, 1, 0)

plotROC(data = hhie, 
  cOutcome = 134, 
  predrisk = pred.nri.binary,
  plottitle = "ROC plot", 
  xlabel = "1 - Specificity", 
  ylabel = "Sensitivity")
# AUC [95% CI] for the model 1 :  0.666 [ 0.626  -  0.706 ]

confusionMatrix(data = as.factor(pred.nri.binary), reference = as.factor(hhie$Purchased_HA), positive = c("1"))

```
   
# Hearing ability (scale of 1 to 10)
Include only participants with self-reported overall hearing ability scores ≤ 7 (case count and %).
```{r, echo=FALSE}
ab <- subset(data2, Ability < 8)
length(ab[,1])
length(ab[,1]) / length(data2[,1]) * 100
```
  
Proportion of people who purchased hearing aids
```{r, echo=FALSE}
table(ab$HA.Purchase)/length(ab[,1]) #0.1440443
```
  
## Hearing ability: Logistic regression with backwards elimination
The full model contains 28 predictors.
```{r, evaluate = FALSE, include = FALSE}

m.ab <- glm(Purchased_HA ~ 
  Age +  
  PTA4_better_ear +
  HHIE_total +
  Ability +
  Sex +
  Edu +
  Married +
  Health +
  QoL +
  Help_neighbours +
  Help_problems +
  Concern +
  Lonely +
  Sub_Age_avg +
  Age_stigma_avg +
  HA_stigma_avg +
  Accomp +
  Soc_Suspect_HL +
  Soc_Know_HL +
  Soc_Discuss_HL +
  Soc_Hearing_test +
  Soc_Obtain_HA +
  Soc_Sometimes_use +
  Soc_Regular_use +
  Soc_Very_positive +
  Soc_Somewhat_positive +
  Soc_Somewhat_negative +
  Soc_Very_negative, 
family = binomial("logit"), data = ab)
```
 
With a backwards elimination procedure, the final model is:
```{r, echo=FALSE, fig.show='hide'}

# step(object = m.ab, direction = c("backward"), trace = 1)
# Only including significant predictors after backwards elimination procedure (dropped additional variables)

m.final <- glm(Purchased_HA ~ Age + PTA4_better_ear + HHIE_total + Sub_Age_avg + Soc_Hearing_test, 
  family = binomial("logit"), data = ab)

summary(m.final)

pseudoR2s(m.final)

pred <- predict.glm(m.final, newdata = subset(ab, select=c('Age', 'PTA4_better_ear', 'HHIE_total', 'Sub_Age_avg', 'Soc_Hearing_test')), type = 'response')
pred.binary <- ifelse(pred > 0.1440443, 1, 0)
    
plotROC(data = ab, 
  cOutcome = 134, 
  predrisk = pred,
  plottitle = "ROC plot", 
  xlabel = "1 - Specificity", 
  ylabel = "Sensitivity")
# AUC [95% CI] for the model 1 :  0.752 [ 0.714  -  0.79 ] 

confusionMatrix(data = as.factor(pred.binary), reference = as.factor(ab$Purchased_HA), positive = c("1"))
```
   
## Hearing ability: Net Reclassification Improvement
"Basic" model: Age only
```{r, echo=FALSE}
m.basic <- glm(Purchased_HA ~ Age, family = binomial("logit"), data = ab)

basic.fitted.results <- predict.glm(m.basic, newdata = subset(ab, select=c('Age')), type = 'response')

summary(m.basic)
``` 
 
Table of NRI values for 27 "novel" predictors 
```{r, eval = FALSE, include = FALSE}

for (i in 1:27) {

new.formula <- as.formula(paste0("Purchased_HA ~ Age + ", predictors[i]))  
m.new <- glm(new.formula, family = binomial("logit"), data = ab)

new.fitted.results <- predict.glm(m.new, newdata = subset(ab, select=c('Age', predictors[i])), type = 'response')

print(predictors[i])
reclassification(data = ab, cOutcome = 134, predrisk1 = basic.fitted.results, predrisk2 = new.fitted.results, cutoff = c(0, 0.1440443, 1))
}
```
 
|Predictor|NRI|p-value| 
|-----|-----|-----| 
|PTA4_better_ear|	0.1374|	0.00064|
|HHIE_total	|0.0679|	0.09917|
|Ability	|-0.0382|	0.2205|
|Sex	|0.0023|	0.8450|
|Edu	|-0.0010|	0.9464|
|Married	|0.0131	|0.2092|
|Health	|-0.0032	|0.8333|
|QoL	|0.0022	|0.7537|
|Help_neighbours	|-0.0160	|0.4712|
|Help_problems	|0.0022|	0.7537|
|Concern	|-0.0010	|0.9353|
|Lonely	|0.0043	|0.0450|
|Sub_Age_avg	|0.0258|	0.2611|
|Age_stigma_avg	|-0.0255	|0.1120|
|HA_stigma_avg	|-0.0041	|0.8639|
|Accomp	|0.0034|	0.8495|
|Soc_Suspect_HL	|-0.0050|	0.7803|
|Soc_Know_HL|	0.0076	|0.3079|
|Soc_Discuss_HL	|0.0108|	0.1582|
|Soc_Hearing_test	|0.0075	|0.7954|
|Soc_Obtain_HA  	|-0.0011|	0.9567|
|Soc_Sometimes_use	|-0.0159	|0.2803|
|Soc_Regular_use	|-0.0063	|0.7725|
|Soc_Very_positive	|0.0034	|0.9088|
|Soc_Somewhat_positive	|0.0141	|0.0748|
|Soc_Somewhat_negative	|0.0067	|0.5843|
|Soc_Very_negative	|-0.0083	|0.5967| 
 
## Hearing ability: Evaluation of regression model containing NRI predictors
```{r, echo=FALSE, fig.show='hide', message = FALSE}

m.nri <- glm(Purchased_HA ~ Age + PTA4_better_ear + Lonely, family = binomial("logit"), data = ab)
summary(m.nri)

exp(coef(m.nri))
exp(cbind(OR = coef(m.nri), confint(m.nri)))

pseudoR2s(m.nri)

pred.nri <- predict.glm(m.nri, newdata = subset(ab, select=c('Age', 'PTA4_better_ear', 'Lonely')), type = 'response')
pred.nri.binary <- ifelse(pred.nri > 0.1440443, 1, 0)

plotROC(data = ab, 
  cOutcome = 134, 
  predrisk = pred.nri.binary,
  plottitle = "ROC plot", 
  xlabel = "1 - Specificity", 
  ylabel = "Sensitivity")
# AUC [95% CI] for the model 1 :  0.674 [ 0.634  -  0.713 ] 

confusionMatrix(data = as.factor(pred.nri.binary), reference = as.factor(ab$Purchased_HA), positive = c("1"))
```  
  