---
title: "Connect1-Stigma merging and cleaning"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

### Read datasets
```{r}
#Questionnaire data: 4630 rows
k <- read.csv("k.csv", header=TRUE)

#Clinic data: 4384 rows
ch <- read.csv("ch.csv", header=TRUE)

#Consent data: 4355 rows
consent <- read.csv("consent.csv", header=TRUE)

```

### Check for duplicate IDs in Questionnaire and Clinic datasets
```{r}

# 4376 of 4384 CH cases are in K
sum(ch[, 'ID'] %in% k[, 'ID'])
# print out 8 cases of CH not in K
ch[which(ch[, 'ID'] %in% kay[, 'ID'] == FALSE), ]

# 4392 of 4630 K cases are in CH
sum(k[, 'ID'] %in% ch[, 'ID'])
# 238 cases of K are not in CH
sum(k[, 'ID'] %in% ch[, 'ID'] == FALSE)
# print out cases of KAY not in CH
k[which(k[, 'ID'] %in% ch[1:4384,] == FALSE), ]

# check for duplicate IDs
length(unique(ch$ID))  #all 4384 cases are unique
length(unique(k$ID))  #4614 are unique (so 16 cases are duplicates)
n_occur <- data.frame(table(k$ID))
k[n_occur$Freq > 1, ]

```

### Merge datasets
```{r}

# add consent data to questionnaire data; rows increased to 4645
cc <- merge(x = k, y = consent, by.x = c("Firstname","Lastname"), by.y = c("Firstname","Lastname"), all.x = TRUE, all.y = FALSE, sort = TRUE)

# a bit of manual cleaning; from 4645 to 4618 rows (still 234 IDs duplicated)

# get rid of duplicate IDs; 4384 cases now, same as clinic data
ccdup <- duplicated(cc$ID)
write.csv(cc[!ccdup, ], "~/Desktop/cc2.csv")

# 2300 of 4384 cases were automatically matched on first and last names

# search function for manually matching fragments of names 
signatures$Fullname <- paste(signatures$Firstname, signatures$Lastname, sep = " ")
frag <- function(string) {
  fraglist <- signatures$Fullname[grep(as.character(string), signatures$Fullname)]
  return(fraglist)
}

# end result: of 4384 cases in Questionnaire dataset, 3544 cases have consent info, 840 have unknown consent status (no info)

# merge with Clinic dataset, 4384 rows
cc2 <- merge(x = cc, y = ch, by.x = c("ID"), by.y = c("ID"), all.x = TRUE, all.y = TRUE, sort = FALSE)

```

### Cleaning
```{r}

# load dataset n=3516 containing questionnaire data, clinic data, consent data; rows have been scrubbed for consent=No
data <- read.csv("Connect_Data_20190730_merged_consent.csv", header=TRUE)

# CORRECTION: blank space in one cell for HA.Purchase.Ear
levels(data$HA.Purchase.Ear)
data[which(data$HA.Purchase.Ear == " Left"), ]
data[data$ID == "C2299619", ]$HA.Purchase.Ear <- "Left"

# CORRECTIONS
data$Q1_Corrected[data$Q1_Corrected == "OTHER" | data$Q1_Corrected == 3.5 | data$Q1_Corrected == 4.5] <- NA
data$Q2_Corrected[data$Q2_Corrected == "OTHER" | data$Q2_Corrected == 1.5 | data$Q2_Corrected == 3.5 | data$Q2_Corrected == 4.5] <- NA
data$Q3_Corrected[data$Q3_Corrected == "OTHER"] <- NA

data$Q4_Corrected[data$Q4_Corrected == "OTHER"] <- NA
data$Q5_Corrected[data$Q5_Corrected == "OTHER"] <- NA
data$Q6_Corrected[data$Q6_Corrected == "OTHER"] <- NA
data$Q7_Corrected[data$Q7_Corrected == "OTHER" | data$Q7_Corrected == 3.5] <- NA
data$Q7_Corrected[data$Q7_Corrected == "1 Strongly Disagree"] <- 1
data$Q7_Corrected[data$Q7_Corrected == "5 Strongly Agree"] <- 5
data$Q8_Corrected[data$Q8_Corrected == "OTHER"] <- NA

data$Q9_Corrected[data$Q9_Corrected == "OTHER"] <- NA
data$Q10_Corrected[data$Q10_Corrected == "OTHER"] <- NA
data$Q11_Corrected[data$Q11_Corrected == "OTHER"] <- NA
data$Q12_Corrected[data$Q12_Corrected == "OTHER"] <- NA

data$Q13_Corrected[data$Q13_Corrected == "OTHER"] <- NA
data$Q14_Corrected[data$Q14_Corrected == "OTHER"] <- NA
data$Q15_Corrected[data$Q15_Corrected == "OTHER"] <- NA
data$Q16_Corrected[data$Q16_Corrected == "OTHER"] <- NA
data$Q17_Corrected[data$Q17_Corrected == "OTHER"] <- NA
data$Q18_Corrected[data$Q18_Corrected == "OTHER"] <- NA
data$Q19_Corrected[data$Q19_Corrected == "OTHER"] <- NA
data$Q20_Corrected[data$Q20_Corrected == "OTHER"] <- NA

data$Q21_Corrected[data$Q21_Corrected == "OTHER"] <- NA
data$Q22_Corrected[data$Q22_Corrected == "OTHER"] <- NA
data$Q23_Corrected[data$Q23_Corrected == "OTHER"] <- NA
data$Q24_Corrected[data$Q24_Corrected == "OTHER"] <- NA
data$Q25_Corrected[data$Q25_Corrected == "OTHER"] <- NA
data$Q26_Corrected[data$Q26_Corrected == "OTHER"] <- NA
data$Q27_Corrected[data$Q27_Corrected == "OTHER"] <- NA
data$Q28_Corrected[data$Q28_Corrected == "OTHER"] <- NA
data$Q29_Corrected[data$Q29_Corrected == "OTHER"] <- NA
data$Q30_Corrected[data$Q30_Corrected == "OTHER"] <- NA
data$Q31_Corrected[data$Q31_Corrected == "OTHER"] <- NA

data$Q32_Corrected[data$Q32_Corrected == "OTHER"] <- NA
data$Q33_Corrected[data$Q33_Corrected == "OTHER"] <- NA
data$Q34_Corrected[data$Q34_Corrected == "OTHER"] <- NA
data$Q35_Corrected[data$Q35_Corrected == "OTHER"] <- NA
data$Q36_Corrected[data$Q36_Corrected == "OTHER"] <- NA
data$Q37_Corrected[data$Q37_Corrected == "OTHER"] <- NA
data$Q38_Corrected[data$Q38_Corrected == "OTHER"] <- NA
data$Q39_Corrected[data$Q39_Corrected == "OTHER"] <- NA
data$Q40_Corrected[data$Q40_Corrected == "OTHER"] <- NA
data$Q41_Corrected[data$Q41_Corrected == "OTHER"] <- NA

data$Q42[grep("\\*Yes has owned, No has Not used", data$Q42)] <- "No"
data$Q42[grep("\\*\"client did Not want to answer\"", data$Q42)] <- NA
data$Q42[grep("^\\*$", data$Q42)] <- NA

data$Q43[grep("^\\*$", data$Q43)] <- NA

data$Q44[grep("^\\*$", data$Q44)] <- NA
data$Q44[grep("\\*63.5", data$Q44)] <- "64" # 63.5 not a factor level
data$Q44[grep("\\*66.5", data$Q44)] <- "67" # 66.5 not a factor level
data$Q44[grep("\\*' 56 or 57", data$Q44)] <- "57" # 56.5 not a factor level
data$Q44[grep("65\\+", data$Q44)] <- "65"
data$Q44[grep("79\\+", data$Q44)] <- "79"

# Check for outliers for Age
boxplot(data$Q44)
table(data$Q44[data$Q44 < 60 & is.na(data$Q44)==FALSE])

data$Q45[grep("^\\*$", data$Q45)] <- NA
data$Q45[grep("\\*yes \"He also has an appointment\"", data$Q45)] <- "Yes"

data$Q46_Corrected[data$Q46_Corrected == "OTHER"] <- NA

# Understanding weird responses for Q47 years of HL
sum(data$Q47_Corrected_years %in% as.character(c(1:99))) #2074 gave an integer answer 1-99
length(data$Q47_Corrected_years[is.na(data$Q47_Corrected_years) == F & data$Q47_Corrected_years == "0"]) # 880 said "0 years"
sum(is.na(data$Q47_Corrected_years)) #136 NA
data$Q47_Corrected_years[!(data$Q47_Corrected_years %in% as.character(c(0:99))) & is.na(data$Q47_Corrected_years)==F]
# CORRECTION: For now, force everything that is not an integer between 1 and 99 into NA
data$Q47_Corrected_years[!(data$Q47_Corrected_years %in% as.character(c(1:99)))] <- NA

# Understanding weird responses for Q48 social circle
sum(data$Q48_Corrected %in% as.character(c(0:500))) #2831 gave an integer answer
sum(is.na(data$Q48_Corrected)) #250
data$Q48_Corrected[!(data$Q48_Corrected %in% as.character(c(0:500))) & is.na(data$Q48_Corrected)==F]
# CORRECTION: For now, force everything that is not an integer between 0 and 500 into NA
data$Q48_Corrected[!(data$Q48_Corrected %in% as.character(c(0:500)))] <- NA

# CORRECTIONS
data$Q49_Corrected[data$Q49_Corrected == "OTHER"] <- NA
data$Q50_Corrected[data$Q50_Corrected == "OTHER"] <- NA

# Weird answers for Q51
length(data$Q51_Corrected[(data$Q51_Corrected %in% c("0", "1_2", "3_5", "5+"))]) #3368 OK
data$Q51_Corrected[!(data$Q51_Corrected %in% c("0", "1_2", "3_5", "5+")) & is.na(data$Q51_Corrected) == F] #22 weird
sum(is.na(data$Q51_Corrected)) #126 NA
# CORRECTIONS
data$Q51_Corrected[grep("&", data$Q51_Corrected)] <- NA
data$Q51_Corrected[grep("[a-zA-Z]", data$Q51_Corrected)] <- NA
data$Q51_Corrected[which(data$Q51_Corrected == '*"1"')] <- "1_2"  # this was tricky
data$Q51_Corrected[grep("10", data$Q51_Corrected)] <- "5+"
data$Q51_Corrected[grep("15\\+", data$Q51_Corrected)] <- "5+"
data$Q51_Corrected[grep("25", data$Q51_Corrected)] <- "5+"
data$Q51_Corrected[grep("50", data$Q51_Corrected)] <- "5+"

# CORRECTIONS
data$Q52_Corrected[data$Q52_Corrected == "OTHER"] <- NA
data$Q53_Corrected[data$Q53_Corrected == "OTHER"] <- NA
data$Q54_Corrected[data$Q54_Corrected == "OTHER"] <- NA
data$Q55_Corrected[data$Q55_Corrected == "OTHER"] <- NA

# How many people have weird hearing ratings?
sum(data$Q56_Corrected %in% as.character(c(1:10))) # 3288 gave integer answer
data$Q56_Corrected[!(data$Q56_Corrected %in% as.character(c(1:10)))]
length(grep("\\.", data$Q56_Corrected)) # 10 people have decimal points
length(grep("&", data$Q56_Corrected)) 
length(grep("and", data$Q56_Corrected)) # 88 people chose more than one category
sum(is.na(data$Q56_Corrected == TRUE)) # 117 NA's
# CORRECTION: Integers between 1 and 10 only
data$Q56_Corrected[!(data$Q56_Corrected %in% as.character(c(1:10)))] <- NA

# What are the weird notations for each frequency in audiogram?
describe(data[, 59:70] )

levels(data$LE250)[!levels(data$LE250) %in% as.character(c(0:120))]
levels(data$LE500)[!levels(data$LE500) %in% as.character(c(0:120))]
levels(data$LE1000)[!levels(data$LE1000) %in% as.character(c(0:120))]
levels(data$LE2000)[!levels(data$LE2000) %in% as.character(c(0:120))]
levels(data$LE4000)[!levels(data$LE4000) %in% as.character(c(0:120))]
levels(data$LE8000)[!levels(data$LE8000) %in% as.character(c(0:120))]

levels(data$RE250)[!levels(data$RE250) %in% as.character(c(0:120))]
levels(data$RE500)[!levels(data$RE500) %in% as.character(c(0:120))]
levels(data$RE1000)[!levels(data$RE1000) %in% as.character(c(0:120))]
levels(data$RE2000)[!levels(data$RE2000) %in% as.character(c(0:120))]
levels(data$RE4000)[!levels(data$RE4000) %in% as.character(c(0:120))]
levels(data$RE8000)[!levels(data$RE8000) %in% as.character(c(0:120))]

# Create new audiogram variables with CORRECTIONS
data$LE250c <- data$LE250
data$LE250c[data$LE250c == "CNT" | data$LE250c == "NR" | data$LE250c == "vt105"] <- 110
data$LE250c <- factor(data$LE250c, levels = c(levels(data$LE250c), "-10"))
data$LE250c[data$LE250c == "_10"] <- -10 #needed new level
data$LE250c[data$LE250c == "_5"] <- -5
data$LE250c[grep("[a-zA-Z]", data$LE250c)] <- NA

data$RE250c <- data$RE250
data$RE250c <- factor(data$RE250c, levels = c(levels(data$RE250c), "110", "-10", "-5"))
data$RE250c[data$RE250c == "CNT" | data$RE250c == "NR" | data$RE250c == "120NR"] <- 110 #needed new level
data$RE250c[data$RE250c == "_10"] <- -10 #needed new level
data$RE250c[data$RE250c == "_5"] <- -5 #needed new level
data$RE250c[grep("\\*2", data$RE250c)] <- NA

data$LE500c <- data$LE500
data$LE500c <- factor(data$LE500c, levels = c(levels(data$LE500c), "125", "-10", "-5"))
data$LE500c[data$LE500c == "CNT" | data$LE500c == "NR" | data$LE500c == "*vt110"] <- 125 #needed new level
data$LE500c[data$LE500c == "_10"] <- -10 #needed new level
data$LE500c[data$LE500c == "_5"] <- -5 #needed new level
data$LE500c[grep("\\*2", data$LE500c)] <- NA
data$LE500c[which(data$LE500c > 200)] <- NA #C2635887

data$RE500c <- data$RE500
data$RE500c <- factor(data$RE500c, levels = c(levels(data$RE500c), "125", "-10"))
data$RE500c[data$RE500c == "CNT" | data$RE500c == "NR" | data$RE500c == "120NR"] <- 125 #needed new level
data$RE500c[data$RE500c == "_10"] <- -10
data$RE500c[data$RE500c == "_5"] <- -5

data$LE1000c <- data$LE1000
data$LE1000c <- factor(data$LE1000c, levels = c(levels(data$LE1000c), "125", "-10"))
data$LE1000c[data$LE1000c == "CNT" | data$LE1000c == "NR"] <- 125 #needed new level
data$LE1000c[data$LE1000c == "_10"] <- -10 #needed new level
data$LE1000c[data$LE1000c == "_5"] <- -5

data$RE1000c <- data$RE1000
data$RE1000c <- factor(data$RE1000c, levels = c(levels(data$RE1000c), "125", "-10"))
data$RE1000c[data$RE1000c == "CNT" | data$RE1000c == "NR" | data$RE1000c == "120NR"] <- 125 #needed new level
data$RE1000c[data$RE1000c == "_10"] <- -10 #needed new level
data$RE1000c[data$RE1000c == "_5"] <- -5

data$LE2000c <- data$LE2000
data$LE2000c <- factor(data$LE2000c, levels = c(levels(data$LE2000c), "125"))
data$LE2000c[data$LE2000c == "CNT" | data$LE2000c == "NR"] <- 125 #needed new level
data$LE2000c[data$LE2000c == "_5"] <- -5
data$LE2000c[data$LE2000c == "35W"] <- 35

data$RE2000c <- data$RE2000
data$RE2000c <- factor(data$RE2000c, levels = c(levels(data$RE2000c), "125", "-5"))
data$RE2000c[data$RE2000c == "CNT" | data$RE2000c == "NR" | data$RE2000c == "120NR"] <- 125 #needed new level
data$RE2000c[data$RE2000c == "100NR"] <- 105
data$RE2000c[data$RE2000c == "_5"] <- -5 #needed new level

data$LE4000c <- data$LE4000
data$LE4000c <- factor(data$LE4000c, levels = c(levels(data$LE4000c), "125"))
data$LE4000c[data$LE4000c == "CNT" | data$LE4000c == "NR"] <- 125 #needed new level
data$LE4000c[data$LE4000c == "_5"] <- -5

data$RE4000c <- data$RE4000
data$RE4000c <- factor(data$RE4000c, levels = c(levels(data$RE4000c), "125"))
data$RE4000c[data$RE4000c == "CNT" | data$RE4000c == "NR" | data$RE4000c == "120NR"] <- 125 #needed new level
data$RE4000c[data$RE4000c == "100NR"] <- 105

data$LE8000c <- data$LE8000
data$LE8000c <- factor(data$LE8000c, levels = c(levels(data$LE8000c), "-10"))
data$LE8000c[data$LE8000c == "CNT" | data$LE8000c == "NR" | data$LE8000c == "100NR"] <- 105
data$LE8000c[data$LE8000c == "95NR"] <- 100
data$LE8000c[data$LE8000c == "90NR"] <- 95
data$LE8000c[grep("\\+", data$LE8000c)] <- 95
data$LE8000c[data$LE8000c == "_5"] <- -5
data$LE8000c[data$LE8000c == "_10"] <- -10 #needed new level

data$RE8000c <- data$RE8000
data$RE8000c <- factor(data$RE8000c, levels = c(levels(data$RE8000c), "105", "120"))
data$RE8000c[data$RE8000c == "CNT" | data$RE8000c == "NR"] <- 105 #needed new level
data$RE8000c[data$RE8000c == "95NR"] <- 100
data$RE8000c[which(data$RE8000c == "95+")] <- 100
data$RE8000c[data$RE8000c == "90NR"] <- 95
data$RE8000c[data$RE8000c == "120NR"] <- 125
data$RE8000c[data$RE8000c == "115NR"] <- 120 #needed new level

# Check for outliers - Thresholds
boxplot(data[, c(83:94)])
# Check for missed typing
which(data[, 83] > 0 & data[, 83] < 5) # C2635887
which(data[, 84] > 0 & data[, 84] < 5) #
which(data[, 85] > 0 & data[, 85] < 5) #
which(data[, 86] > 0 & data[, 86] < 5) #
which(data[, 87] > 0 & data[, 87] < 5) # C2632572, C2635887
which(data[, 88] > 0 & data[, 88] < 5) #
which(data[, 89] > 0 & data[, 89] < 5) #
which(data[, 90] > 0 & data[, 90] < 5) #
which(data[, 91] > 0 & data[, 91] < 5) #
which(data[, 92] > 0 & data[, 92] < 5) #
which(data[, 93] > 0 & data[, 93] < 5) #
which(data[, 94] > 0 & data[, 94] < 5) # C2640503

# final check of variables
write.csv(data, "~/Desktop/Connect_Data_20190730_merged_consent_cleaned.csv")
clean <- read.csv("~/Desktop/Connect_Data_20190730_merged_consent_cleaned", header=TRUE)
str(clean, list.len = 120)

```

